{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cancer dataset Classification Methods Alina Eresheeva.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlwWPfGoQ63eBa/QZP7wx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eresheevaa/School-Coding-Alina-Eresheeva/blob/main/Cancer_dataset_Classification_Methods_Alina_Eresheeva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twcNS9xumW6G"
      },
      "source": [
        "### KNN Classification Method\n",
        "#The K-nearest-neighbors (KNN) classification algorithm is based on the premise “If it walks like duck and quacks like a duck, it’s a duck.” \n",
        "#To use KNN, you provide a value for the number K that specifies the number of neighboring training set values to which a value must be similar \n",
        "#in order to be considered part of a group. \n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "names = ['Sample', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', \n",
        "         'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'class']\n",
        "\n",
        "df = pd.read_csv('Breast.Data (1).csv', header= None, names=names)\n",
        "X = np.array(df.iloc[:, 1:10])\n",
        "y = np.array(df['class'])\n",
        "\n",
        "#split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wrncAxR0l_H",
        "outputId": "7a972970-a303-40df-bbc1-58ecc7374f06"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "pred = knn.predict(X_test)\n",
        "\n",
        "print('\\nModel accuracy score: ', accuracy_score(y_test, pred))\n",
        "print(confusion_matrix(y_test,pred))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model accuracy score:  0.975609756097561\n",
            "[[129   2]\n",
            " [  3  71]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "547aN3Op2PQG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUC4pZ7_2QEe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjULQTKg2QMc"
      },
      "source": [
        "### LOGISTIC REGRESSION CLASSIFICATION ON IRIS DATASET\n",
        "#The logistic regression classifier is best suited for binary-dependent variables—classifications for which there are only two classes, \n",
        "#such as gender, a tumor being malignant or benign, and so on. You can use logistic regression for multiclass problems,\n",
        "#but your results may not prove as accurate as other methods. \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "names = ['Sample', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', \n",
        "         'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'class']\n",
        "\n",
        "df = pd.read_csv('Breast.Data (1).csv', header= None, names=names)\n",
        "X = np.array(df.iloc[:, 1:10])\n",
        "y = np.array(df['class'])\n",
        "\n",
        "#split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3mgi1QU2upQ"
      },
      "source": [
        "model = LogisticRegression(solver='lbfgs').fit(X_train,y_train)\n",
        "pred = model.predict(X_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk45LR8R24Tk",
        "outputId": "868a073a-b8c0-418f-b8b7-0aff85c07e56"
      },
      "source": [
        "print('\\nAccuracy score: ', accuracy_score(y_test, pred))\n",
        "print(confusion_matrix(y_test,pred))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy score:  0.9707317073170731\n",
            "[[125   5]\n",
            " [  1  74]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBVIJV7W29FM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRuboKn-3Aeg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz_VZe2u3Amj"
      },
      "source": [
        "### DECISION TREE CLASSIFICATION METHOD\n",
        "# A decision tree is a graph-based data structure that a program can use to follow a series of decision paths to arrive at a decision. \n",
        "#This figure illustrates a decision tree that determines a student’s test grade.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import sklearn.tree as tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "names = ['Sample', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', \n",
        "         'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'class']\n",
        "\n",
        "df = pd.read_csv('Breast.Data (1).csv', header= None, names=names)\n",
        "X = np.array(df.iloc[:, 1:10])\n",
        "y = np.array(df['class'])\n",
        "\n",
        "#split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huAEEl4S3ieo",
        "outputId": "a6e0d9b1-ba8e-4ec0-a578-6ef2f70275c4"
      },
      "source": [
        "DT = tree.DecisionTreeClassifier()\n",
        "DT.fit(X_train, y_train)\n",
        "pred = DT.predict(X_test)\n",
        "\n",
        "print('\\nAccuracy score: ', accuracy_score(y_test, pred))\n",
        "print('\\nConfusion Matrix\\n', confusion_matrix(y_test, pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy score:  0.9317073170731708\n",
            "\n",
            "Confusion Matrix\n",
            " [[121   8]\n",
            " [  6  70]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30GSZ-jX4JHK",
        "outputId": "07feef9e-3124-4819-bca5-412211308f6d"
      },
      "source": [
        "# Viewing the decision tree\n",
        "\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(DT, out_file='DecisionTree.dot')\n",
        "\n",
        "with open('DecisionTree.dot') as f:\n",
        "  dot_graph = f.read()\n",
        "\n",
        "g = graphviz.Source(dot_graph)\n",
        "g.render()\n",
        "\n",
        "print('PDF created')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEHHCZke41kt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdv1Th2c5kt4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeHgUFUa5k0f"
      },
      "source": [
        "### RANDOM FOREST CLASSIFICATON \n",
        "# Depending on the data set and model, there may be times when the decision tree becomes very deep (many levels of nodes). \n",
        "# These decision trees will overfill the data and will have a large variance. \n",
        "# A random-forest classification model creates many different decision trees for a data set and then, based on each tree’s prediction, \n",
        "# the trees essentially vote to select the tree that produces the best result.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import sklearn.tree as tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "names = ['Sample', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', \n",
        "         'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'class']\n",
        "\n",
        "df = pd.read_csv('Breast.Data (1).csv', header= None, names=names)\n",
        "X = np.array(df.iloc[:, 1:10])\n",
        "y = np.array(df['class'])\n",
        "\n",
        "#split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkmAnX1H5-DE"
      },
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(X_train,y_train)\n",
        "pred = model.predict(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8Oj7QUO6NuH",
        "outputId": "5576165b-7748-4115-dffc-a469e084599f"
      },
      "source": [
        "print('\\nAccuracy score: ', accuracy_score(y_test, pred))\n",
        "print('\\nConfusion matrix:\\n' , confusion_matrix(y_test,pred))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy score:  0.9707317073170731\n",
            "\n",
            "Confusion matrix:\n",
            " [[125   5]\n",
            " [  1  74]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-xa-7Mj6j78"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N6iZnjj6w13"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gv4f6BT6w9p"
      },
      "source": [
        "### SUPPORT VECTOR MACHINE CLASSIFYING (SVM) OR SUPPORT VECTOR CLASSIFIER (SVC)\n",
        "# The support vector machine (SVM), also called an SVC (support vector classifier) classifies data by separating values with a line called a hyperplane.\n",
        "# Classes that you can separate using a line are said to be linearly separable. As you can see, there are many lines you can use to divide the classes.\n",
        "# The goal of SVC is to find the line that creates the widest separation between the classes. \n",
        "#To calculate the best separation line, the algorithm uses two additional lines called support vectors.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "names = ['Sample', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', \n",
        "         'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'class']\n",
        "\n",
        "df = pd.read_csv('Breast.Data (1).csv', header= None, names=names)\n",
        "X = np.array(df.iloc[:, 1:10])\n",
        "y = np.array(df['class'])\n",
        "\n",
        "#split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30) "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22xH5Lx6632H",
        "outputId": "b52c3ae4-a27b-4a39-c152-1c5a4f7618d4"
      },
      "source": [
        "model = SVC(gamma = 'auto').fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "print('\\nModel accuracy score: ', accuracy_score(y_test,pred))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model accuracy score:  0.9463414634146341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FMJsUI0699o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}